{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJD3JEpllWIn",
        "outputId": "5f986b0b-67ba-42b0-f4d2-fb0c4aa889e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KehgemGblZ4V",
        "outputId": "df294258-053e-4482-c06d-c80641149a33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Thesis_work/DGCNN/dgcnn/pytorch\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/Thesis_work/DGCNN/dgcnn/pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install open3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RD5SEScLlFAH",
        "outputId": "a55611d7-be42-4c5b-b171-10ffe006e4ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting open3d\n",
            "  Downloading open3d-0.14.1-cp37-cp37m-manylinux_2_27_x86_64.whl (395.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 395.5 MB 29 kB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.4.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 59.1 MB/s \n",
            "\u001b[?25hCollecting jupyterlab==3.*,>=3.0.0\n",
            "  Downloading jupyterlab-3.2.8-py3-none-any.whl (8.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.5 MB 72.7 MB/s \n",
            "\u001b[?25hCollecting pygments>=2.7.4\n",
            "  Downloading Pygments-2.11.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 60.4 MB/s \n",
            "\u001b[?25hCollecting jupyter-packaging~=0.10\n",
            "  Downloading jupyter_packaging-0.11.1-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.7/dist-packages (from open3d) (3.2.2)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.7/dist-packages (from open3d) (1.1.5)\n",
            "Collecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from open3d) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.7/dist-packages (from open3d) (1.0.2)\n",
            "Collecting pillow>=8.2.0\n",
            "  Downloading Pillow-9.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 56.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipywidgets>=7.6.0 in /usr/local/lib/python3.7/dist-packages (from open3d) (7.6.5)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.7/dist-packages (from open3d) (57.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from open3d) (4.62.3)\n",
            "Requirement already satisfied: wheel>=0.36.0 in /usr/local/lib/python3.7/dist-packages (from open3d) (0.37.1)\n",
            "Collecting jupyterlab-server~=2.3\n",
            "  Downloading jupyterlab_server-2.10.3-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 10.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.*,>=3.0.0->open3d) (4.9.1)\n",
            "Collecting tornado>=6.1.0\n",
            "  Downloading tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl (428 kB)\n",
            "\u001b[K     |████████████████████████████████| 428 kB 77.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.*,>=3.0.0->open3d) (21.3)\n",
            "Requirement already satisfied: jinja2>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.*,>=3.0.0->open3d) (2.11.3)\n",
            "Collecting jupyter-server~=1.4\n",
            "  Downloading jupyter_server-1.13.4-py3-none-any.whl (395 kB)\n",
            "\u001b[K     |████████████████████████████████| 395 kB 71.9 MB/s \n",
            "\u001b[?25hCollecting nbclassic~=0.2\n",
            "  Downloading nbclassic-0.3.5-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.*,>=3.0.0->open3d) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->open3d) (3.5.2)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->open3d) (5.1.3)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->open3d) (4.10.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->open3d) (1.0.2)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->open3d) (5.1.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->open3d) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->open3d) (5.3.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.*,>=3.0.0->open3d) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.*,>=3.0.0->open3d) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.*,>=3.0.0->open3d) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.*,>=3.0.0->open3d) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.*,>=3.0.0->open3d) (0.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.1->jupyterlab==3.*,>=3.0.0->open3d) (2.0.1)\n",
            "Collecting deprecation\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting tomlkit\n",
            "  Downloading tomlkit-0.8.0-py3-none-any.whl (33 kB)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.4->jupyterlab==3.*,>=3.0.0->open3d) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.4->jupyterlab==3.*,>=3.0.0->open3d) (22.3.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.4->jupyterlab==3.*,>=3.0.0->open3d) (21.3.0)\n",
            "Collecting jupyter-client\n",
            "  Downloading jupyter_client-7.1.2-py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 78.4 MB/s \n",
            "\u001b[?25hCollecting anyio<4,>=3.1.0\n",
            "  Downloading anyio-3.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 10.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.4->jupyterlab==3.*,>=3.0.0->open3d) (0.12.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.4->jupyterlab==3.*,>=3.0.0->open3d) (0.12.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.4->jupyterlab==3.*,>=3.0.0->open3d) (5.6.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.1.0->jupyter-server~=1.4->jupyterlab==3.*,>=3.0.0->open3d) (3.10.0.2)\n",
            "Collecting sniffio>=1.1\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.1.0->jupyter-server~=1.4->jupyterlab==3.*,>=3.0.0->open3d) (2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.6.0->open3d) (2.8.2)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.6.0->open3d) (1.5.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.6.0->open3d) (0.3)\n",
            "Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.3->jupyterlab==3.*,>=3.0.0->open3d) (4.3.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.3->jupyterlab==3.*,>=3.0.0->open3d) (2.23.0)\n",
            "Collecting json5\n",
            "  Downloading json5-0.9.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.3->jupyterlab==3.*,>=3.0.0->open3d) (2.9.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.3->jupyterlab==3.*,>=3.0.0->open3d) (5.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.3->jupyterlab==3.*,>=3.0.0->open3d) (4.10.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.3->jupyterlab==3.*,>=3.0.0->open3d) (21.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.3->jupyterlab==3.*,>=3.0.0->open3d) (0.18.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.0.1->jupyterlab-server~=2.3->jupyterlab==3.*,>=3.0.0->open3d) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3->open3d) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3->open3d) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3->open3d) (1.3.2)\n",
            "Requirement already satisfied: notebook<7 in /usr/local/lib/python3.7/dist-packages (from nbclassic~=0.2->jupyterlab==3.*,>=3.0.0->open3d) (5.3.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->open3d) (2018.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->jupyterlab==3.*,>=3.0.0->open3d) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->jupyterlab==3.*,>=3.0.0->open3d) (0.2.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21->open3d) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21->open3d) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21->open3d) (1.1.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.3->jupyter-server~=1.4->jupyterlab==3.*,>=3.0.0->open3d) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.7/dist-packages (from argon2-cffi->jupyter-server~=1.4->jupyterlab==3.*,>=3.0.0->open3d) (21.2.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.4->jupyterlab==3.*,>=3.0.0->open3d) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.4->jupyterlab==3.*,>=3.0.0->open3d) (2.21)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.4->jupyterlab==3.*,>=3.0.0->open3d) (4.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.4->jupyterlab==3.*,>=3.0.0->open3d) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.4->jupyterlab==3.*,>=3.0.0->open3d) (0.5.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.4->jupyterlab==3.*,>=3.0.0->open3d) (1.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.4->jupyterlab==3.*,>=3.0.0->open3d) (0.8.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter-server~=1.4->jupyterlab==3.*,>=3.0.0->open3d) (0.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.3->jupyterlab==3.*,>=3.0.0->open3d) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.3->jupyterlab==3.*,>=3.0.0->open3d) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.3->jupyterlab==3.*,>=3.0.0->open3d) (3.0.4)\n",
            "Installing collected packages: tornado, pygments, sniffio, jupyter-client, websocket-client, anyio, jupyter-server, json5, tomlkit, nbclassic, jupyterlab-server, deprecation, pyyaml, pillow, jupyterlab, jupyter-packaging, addict, open3d\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 5.1.1\n",
            "    Uninstalling tornado-5.1.1:\n",
            "      Successfully uninstalled tornado-5.1.1\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 5.3.5\n",
            "    Uninstalling jupyter-client-5.3.5:\n",
            "      Successfully uninstalled jupyter-client-5.3.5\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed addict-2.4.0 anyio-3.5.0 deprecation-2.1.0 json5-0.9.6 jupyter-client-7.1.2 jupyter-packaging-0.11.1 jupyter-server-1.13.4 jupyterlab-3.2.8 jupyterlab-server-2.10.3 nbclassic-0.3.5 open3d-0.14.1 pillow-9.0.0 pygments-2.11.2 pyyaml-6.0 sniffio-1.2.0 tomlkit-0.8.0 tornado-6.1 websocket-client-1.2.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "jupyter_client",
                  "pygments",
                  "tornado"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YW_6JoInlnLR"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from data import ModelNet40\n",
        "from model import PointNet, DGCNN\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from util import cal_loss, IOStream\n",
        "import sklearn.metrics as metrics\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import open3d as o3d\n",
        "\n",
        "import sys\n",
        "import copy\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxwWBk5xlrEh",
        "outputId": "348b8183-b0f5-4d94-fa1f-f7a08aec48c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting path.py\n",
            "  Downloading path.py-12.5.0-py3-none-any.whl (2.3 kB)\n",
            "Collecting path\n",
            "  Downloading path-16.3.0-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: path, path.py\n",
            "Successfully installed path-16.3.0 path.py-12.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install path.py;\n",
        "from path import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1q4cw6qltge",
        "outputId": "13414fdb-6e08-4f9d-ea33-a9e204bef973"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Thesis_work/Datasets/RGBD Dataset\n"
          ]
        }
      ],
      "source": [
        "path = Path(\"/content/gdrive/MyDrive/Thesis_work/Datasets/RGBD Dataset\")\n",
        "random.seed = 49\n",
        "print(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SABhpyTflyPu",
        "outputId": "b00b67f0-930e-4b14-d46c-2af6f7a1b893"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'apple': 0,\n",
              " 'binder': 1,\n",
              " 'calculator': 2,\n",
              " 'cereal_box': 3,\n",
              " 'coffee_mug': 4,\n",
              " 'dry_battery': 5,\n",
              " 'flashlight': 6,\n",
              " 'food_can': 7,\n",
              " 'food_cup': 8,\n",
              " 'garlic': 9,\n",
              " 'greens': 10,\n",
              " 'keyboard': 11,\n",
              " 'kleenex': 12,\n",
              " 'lightbulb': 13,\n",
              " 'lime': 14,\n",
              " 'mushroom': 15,\n",
              " 'notebook': 16,\n",
              " 'onion': 17,\n",
              " 'pear': 18,\n",
              " 'pitcher': 19,\n",
              " 'potato': 20,\n",
              " 'soda_can': 21,\n",
              " 'sponge': 22,\n",
              " 'toothpaste': 23,\n",
              " 'water_bottle': 24}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "folders = [dir for dir in sorted(os.listdir(path)) if os.path.isdir(path/dir)]\n",
        "classes = {folder: i for i, folder in enumerate(folders)};\n",
        "classes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pcd file read function"
      ],
      "metadata": {
        "id": "2JZWijdiigeh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zr2oJpOl1Za"
      },
      "outputs": [],
      "source": [
        "def read_pcd(file):\n",
        "    pcd = o3d.io.read_point_cloud(file, format=\"xyz\")\n",
        "    points = np.asarray(pcd.points)  \n",
        "    return points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Lpm8WjFl7Ky"
      },
      "outputs": [],
      "source": [
        "class PointSampler(object):\n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, int)\n",
        "        self.output_size = output_size\n",
        "    \n",
        "    def sample_point(self, pt1, pt2, pt3):\n",
        "        # barycentric coordinates on a triangle\n",
        "        # https://mathworld.wolfram.com/BarycentricCoordinates.html\n",
        "        s, t = sorted([random.random(), random.random()])\n",
        "        f = lambda i: s * pt1[i] + (t-s)*pt2[i] + (1-t)*pt3[i]\n",
        "        return (f(0), f(1), f(2))\n",
        "          \n",
        "    def __call__(self, mesh):\n",
        "        verts = mesh\n",
        "        verts = np.array(verts)\n",
        "        sampled_points = np.array(random.choices(verts, \n",
        "                                      k=self.output_size))\n",
        "        \n",
        "        return sampled_points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQYxi9EQmBEd"
      },
      "outputs": [],
      "source": [
        "class ToTensor(object):\n",
        "    def __call__(self, pointcloud):\n",
        "        assert len(pointcloud.shape)==2\n",
        "\n",
        "        return torch.from_numpy(pointcloud)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pny8t0qHmE0-"
      },
      "outputs": [],
      "source": [
        "class Normalize(object):\n",
        "    def __call__(self, pointcloud):\n",
        "        assert len(pointcloud.shape)==2\n",
        "        \n",
        "        norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0) \n",
        "        norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n",
        "\n",
        "        return  norm_pointcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIE4q6KumJys"
      },
      "outputs": [],
      "source": [
        "def default_transforms():\n",
        "    return transforms.Compose([\n",
        "                                PointSampler(1024),\n",
        "                                Normalize(),\n",
        "                                ToTensor()\n",
        "                              ])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "                    PointSampler(1024),\n",
        "                    Normalize(),\n",
        "                    ToTensor()\n",
        "                    ])"
      ],
      "metadata": {
        "id": "dw1lGNSgjkU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zREqxQBAmMat"
      },
      "outputs": [],
      "source": [
        "class PointCloudData(Dataset):\n",
        "    def __init__(self, files, classes, transform=train_transforms):\n",
        "        self.files = files\n",
        "        self.classes = classes\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pcd_path = self.files[idx]['pcd_path']\n",
        "        category = self.files[idx]['category']\n",
        "        return {'pointcloud': self.transform((read_pcd(pcd_path))), \n",
        "                'category': self.classes[category]}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ds(root_dir):\n",
        "    folders = [dir for dir in sorted(os.listdir(root_dir))]\n",
        "    classes = {folder: i for i, folder in enumerate(folders)}\n",
        "    train_files = []\n",
        "    valid_files = []\n",
        "    for category in classes.keys():\n",
        "        train_folders = [dir for dir in sorted(os.listdir(root_dir+\"/\"+category))]\n",
        "        valid_folder = train_folders.pop()\n",
        "        for folder in train_folders:\n",
        "            new_dir = root_dir/Path(category)/folder\n",
        "            dir = sorted(os.listdir(new_dir))[::4]\n",
        "            for file in dir:\n",
        "                if file.endswith('.pcd'):\n",
        "                    sample = {}\n",
        "                    sample['pcd_path'] = new_dir/file\n",
        "                    sample['category'] = category\n",
        "                    train_files.append(sample)\n",
        "        new_dir = root_dir/Path(category)/valid_folder\n",
        "        valid_dir = root_dir/Path(category)/valid_folder\n",
        "        valid_dir = sorted(os.listdir(valid_dir))[::4]\n",
        "        for file in valid_dir:\n",
        "            if file.endswith('.pcd'):\n",
        "                sample = {}\n",
        "                sample['pcd_path'] = new_dir/file\n",
        "                sample['category'] = category\n",
        "                valid_files.append(sample)\n",
        "    return train_files, valid_files"
      ],
      "metadata": {
        "id": "tqnWmE7qjzZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWcjG9lqmX5y"
      },
      "outputs": [],
      "source": [
        "train_files, valid_files = ds(path)\n",
        "train_ds = PointCloudData(train_files, classes, transform=train_transforms)\n",
        "valid_ds = PointCloudData(valid_files, classes, transform=train_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuBk_WjVwCKZ",
        "outputId": "65d9e7e1-a7be-426b-96d2-14b46f39b056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_w39kZimyqs",
        "outputId": "5790409c-edfd-4d7b-ddfe-5f6aa5e622f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading all train PCD files \n",
            "Samples read: 0-100-200-300-400-500-600-700-800-900-1000-1100-1200-1300-1400-1500-1600-1700-1800-1900-2000-2100-2200-2300-2400-2500-2600-2700-2800-2900-3000-3100-3200-3300-3400-3500-3600-3700-3800-3900-4000-4100-4200-4300-4400-4500-4600-4700-4800-4900-5000-5100-5200-5300-5400-5500-5600-5700-5800-5900-6000-6100-6200-6300-6400-6500-6600-6700-6800-6900-7000-7100-7200-7300-7400-7500-7600-7700-7800-7900-8000-8100-8200-8300-8400-8500-8600-8700-8800-8900-9000-9100-9200-9300-9400-9500-9600-9700-9800-9900-10000-10100-10200-10300-10400-10500-"
          ]
        }
      ],
      "source": [
        "print(\"Reading all train PCD files \\nSamples read:\",end=\" \")\n",
        "X = []\n",
        "for i in range(len(train_ds)):\n",
        "    if i%100==0:\n",
        "        print(i,end=\"-\")\n",
        "    X.append(train_ds[i])   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCzUR2dom9by",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "090265c4-067d-492e-e8fd-937638905bb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading all valid PCD files \n",
            "Samples read: 0-100-200-300-400-500-600-700-800-900-1000-1100-1200-1300-1400-1500-1600-1700-1800-1900-2000-2100-2200-2300-2400-2500-"
          ]
        }
      ],
      "source": [
        "print(\"Reading all valid PCD files \\nSamples read:\",end=\" \")\n",
        "X_val = []\n",
        "for i in range(len(valid_ds)):\n",
        "    if i%100==0:\n",
        "        print(i,end=\"-\")\n",
        "    X_val.append(valid_ds[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Gc-sK36nBO0"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset=X, batch_size=32, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(dataset=X_val, batch_size=16, shuffle=False, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_hDbPlMnNp-"
      },
      "outputs": [],
      "source": [
        "def knn(x, k):\n",
        "    inner = -2*torch.matmul(x.transpose(2, 1), x)\n",
        "    xx = torch.sum(x**2, dim=1, keepdim=True)\n",
        "    pairwise_distance = -xx - inner - xx.transpose(2, 1)\n",
        " \n",
        "    idx = pairwise_distance.topk(k=k, dim=-1)[1]   # (batch_size, num_points, k)\n",
        "    return idx\n",
        "\n",
        "\n",
        "def get_graph_feature(x, k=20, idx=None):\n",
        "    batch_size = x.size(0)\n",
        "    num_points = x.size(2)\n",
        "    x = x.view(batch_size, -1, num_points)\n",
        "    if idx is None:\n",
        "        idx = knn(x, k=k)   # (batch_size, num_points, k)\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "    idx_base = torch.arange(0, batch_size, device=device).view(-1, 1, 1)*num_points\n",
        "\n",
        "    idx = idx + idx_base\n",
        "\n",
        "    idx = idx.view(-1)\n",
        " \n",
        "    _, num_dims, _ = x.size()\n",
        "\n",
        "    x = x.transpose(2, 1).contiguous()   # (batch_size, num_points, num_dims)  -> (batch_size*num_points, num_dims) #   batch_size * num_points * k + range(0, batch_size*num_points)\n",
        "    feature = x.view(batch_size*num_points, -1)[idx, :]\n",
        "    feature = feature.view(batch_size, num_points, k, num_dims) \n",
        "    x = x.view(batch_size, num_points, 1, num_dims).repeat(1, 1, k, 1)\n",
        "    \n",
        "    feature = torch.cat((feature-x, x), dim=3).permute(0, 3, 1, 2).contiguous()\n",
        "  \n",
        "    return feature\n",
        "\n",
        "class DGCNN(nn.Module):\n",
        "    def __init__(self, output_channels=30):\n",
        "        super(DGCNN, self).__init__()\n",
        "        self.k = 20\n",
        "        \n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.bn5 = nn.BatchNorm1d(1024)\n",
        "\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(6, 64, kernel_size=1, bias=False),\n",
        "                                   self.bn1,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(64*2, 64, kernel_size=1, bias=False),\n",
        "                                   self.bn2,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(64*2, 128, kernel_size=1, bias=False),\n",
        "                                   self.bn3,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv4 = nn.Sequential(nn.Conv2d(128*2, 256, kernel_size=1, bias=False),\n",
        "                                   self.bn4,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv5 = nn.Sequential(nn.Conv1d(512, 1024, kernel_size=1, bias=False),\n",
        "                                   self.bn5,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.linear1 = nn.Linear(1024*2, 512, bias=False)\n",
        "        self.bn6 = nn.BatchNorm1d(512)\n",
        "        self.dp1 = nn.Dropout(p=0.6)\n",
        "        self.linear2 = nn.Linear(512, 256)\n",
        "        self.bn7 = nn.BatchNorm1d(256)\n",
        "        self.dp2 = nn.Dropout(p=0.6)\n",
        "        self.linear3 = nn.Linear(256, output_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x = get_graph_feature(x, k=self.k)\n",
        "        x = self.conv1(x)\n",
        "        x1 = x.max(dim=-1, keepdim=False)[0]\n",
        "\n",
        "        x = get_graph_feature(x1, k=self.k)\n",
        "        x = self.conv2(x)\n",
        "        x2 = x.max(dim=-1, keepdim=False)[0]\n",
        "\n",
        "        x = get_graph_feature(x2, k=self.k)\n",
        "        x = self.conv3(x)\n",
        "        x3 = x.max(dim=-1, keepdim=False)[0]\n",
        "      \n",
        "        x = get_graph_feature(x3, k=self.k)\n",
        "        x = self.conv4(x)\n",
        "        x4 = x.max(dim=-1, keepdim=False)[0]\n",
        "      \n",
        "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "  \n",
        "        x1 = F.adaptive_max_pool1d(x, 1).view(batch_size, -1)\n",
        "        x2 = F.adaptive_avg_pool1d(x, 1).view(batch_size, -1)\n",
        "        x = torch.cat((x1, x2), 1)\n",
        "        \n",
        "        x = F.leaky_relu(self.bn6(self.linear1(x)), negative_slope=0.2)\n",
        "        x = self.dp1(x)\n",
        "        x = F.leaky_relu(self.bn7(self.linear2(x)), negative_slope=0.2)\n",
        "        x = self.dp2(x)\n",
        "        x = self.linear3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfPUyefVxZs3"
      },
      "outputs": [],
      "source": [
        "def train(epochs,model,train_loader,test_loader, sgd, lr, momentum):\n",
        "    \n",
        "    #Try to load models\n",
        "    # if args.model == 'pointnet':\n",
        "    #     model = PointNet(args).to(device)\n",
        "    # elif args.model == 'dgcnn':\n",
        "    #     model = DGCNN(args).to(device)\n",
        "    # else:\n",
        "    #     raise Exception(\"Not implemented\")\n",
        "    # print(str(model))\n",
        "    \n",
        "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    \n",
        "    PATH = \"dgcnn.pth\"\n",
        "#     checkpoint = torch.load(PATH)\n",
        "#     model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "    if sgd:\n",
        "        print(\"Use SGD\")\n",
        "        opt = optim.SGD(model.parameters(), lr=lr*100, momentum=momentum, weight_decay=1e-4)\n",
        "    else:\n",
        "        print(\"Use Adam\")\n",
        "        opt = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "\n",
        "    scheduler = CosineAnnealingLR(opt, epochs, eta_min=0.0001)\n",
        "    \n",
        "    criterion = cal_loss\n",
        "\n",
        "    best_test_acc = 0\n",
        "    for epoch in range(epochs):\n",
        "        opt.step()\n",
        "        scheduler.step()\n",
        "        ####################\n",
        "        # Train\n",
        "        ####################\n",
        "        train_loss = 0.0\n",
        "        count = 0.0\n",
        "        model.train()\n",
        "        train_pred = []\n",
        "        train_true = []\n",
        "        for data in train_loader:\n",
        "            label = data['category'].to(device)\n",
        "            data  = data['pointcloud'].to(device).float() \n",
        "            data = data.permute(0, 2, 1)\n",
        "            batch_size = data.size()[0]\n",
        "            opt.zero_grad()\n",
        "            logits = model(data)\n",
        "            loss = criterion(logits, label)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            preds = logits.max(dim=1)[1]\n",
        "            count += batch_size\n",
        "            train_loss += loss.item() * batch_size\n",
        "            train_true.append(label.cpu().numpy())\n",
        "            train_pred.append(preds.detach().cpu().numpy())\n",
        "        train_true = np.concatenate(train_true)\n",
        "        train_pred = np.concatenate(train_pred)\n",
        "        # torch.save(model.state_dict(), \"save_\"+str(epoch)+\".pth\")\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': opt.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, \"dgcnn_\"+str(epoch)+\".pth\")\n",
        "        outstr = 'Train %d, loss: %.6f, train acc: %.6f, train avg acc: %.6f' % (epoch,\n",
        "                                                                                 train_loss*1.0/count,\n",
        "                                                                                 metrics.accuracy_score(\n",
        "                                                                                     train_true, train_pred),\n",
        "                                                                                 metrics.balanced_accuracy_score(\n",
        "                                                                                     train_true, train_pred))\n",
        "        print(outstr)\n",
        "\n",
        "        ####################\n",
        "        # Test\n",
        "        ####################\n",
        "        test_loss = 0.0\n",
        "        count = 0.0\n",
        "        model.eval()\n",
        "        test_pred = []\n",
        "        test_true = []\n",
        "        for data in test_loader:\n",
        "            label = data['category'].to(device).squeeze()\n",
        "            data= data['pointcloud'].to(device).float() \n",
        "            data = data.permute(0, 2, 1)\n",
        "            batch_size = data.size()[0]\n",
        "            logits = model(data)\n",
        "            loss = criterion(logits, label)\n",
        "            preds = logits.max(dim=1)[1]\n",
        "            count += batch_size\n",
        "            test_loss += loss.item() * batch_size\n",
        "            test_true.append(label.cpu().numpy())\n",
        "            test_pred.append(preds.detach().cpu().numpy())\n",
        "        test_true = np.concatenate(test_true)\n",
        "        test_pred = np.concatenate(test_pred)\n",
        "        test_acc = metrics.accuracy_score(test_true, test_pred)\n",
        "        avg_per_class_acc = metrics.balanced_accuracy_score(test_true, test_pred)\n",
        "        outstr = 'Test %d, loss: %.6f, test acc: %.6f, test avg acc: %.6f' % (epoch,\n",
        "                                                                              test_loss*1.0/count,\n",
        "                                                                              test_acc,\n",
        "                                                                              avg_per_class_acc)\n",
        "        print(outstr)\n",
        "        if test_acc >= best_test_acc:\n",
        "            best_test_acc = test_acc\n",
        "            #torch.save(model.state_dict(), 'checkpoints/%s/models/model.t7' % args.exp_name)\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': opt.state_dict(),\n",
        "                'loss': loss,\n",
        "                }, \"dgcnn_rgbd_\"+str(epoch)+\"_\"+str(best_test_acc+\".pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYykN5ZUna7B"
      },
      "outputs": [],
      "source": [
        "def train(epochs,train_loader,test_loader, sgd, lr, momentum):\n",
        "    # train_loader = DataLoader(ModelNet40(partition='train', num_points=args.num_points), num_workers=8,\n",
        "    #                           batch_size=args.batch_size, shuffle=True, drop_last=True)\n",
        "    # test_loader = DataLoader(ModelNet40(partition='test', num_points=args.num_points), num_workers=8,\n",
        "    #                          batch_size=args.test_batch_size, shuffle=True, drop_last=False)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    #Try to load models\n",
        "    # if args.model == 'pointnet':\n",
        "    #     model = PointNet(args).to(device)\n",
        "    # elif args.model == 'dgcnn':\n",
        "    #     model = DGCNN(args).to(device)\n",
        "    # else:\n",
        "    #     raise Exception(\"Not implemented\")\n",
        "    # print(str(model))\n",
        "    model = DGCNN().to(device)\n",
        "    model = nn.DataParallel(model)\n",
        "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    \n",
        "    PATH = \"/content/gdrive/MyDrive/Thesis_work/DGCNN/dgcnn/pytorch/dgcnn_13_86.pth\"\n",
        "    checkpoint = torch.load(PATH)\n",
        "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "    if sgd:\n",
        "        print(\"Use SGD\")\n",
        "        opt = optim.SGD(model.parameters(), lr=lr*100, momentum=momentum, weight_decay=1e-4)\n",
        "    else:\n",
        "        print(\"Use Adam\")\n",
        "        opt = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "\n",
        "    scheduler = CosineAnnealingLR(opt, epochs, eta_min=0.0001)\n",
        "    \n",
        "    criterion = cal_loss\n",
        "\n",
        "    best_test_acc = 0\n",
        "    for epoch in range(epochs):\n",
        "        opt.step()\n",
        "        scheduler.step()\n",
        "        ####################\n",
        "        # Train\n",
        "        ####################\n",
        "        train_loss = 0.0\n",
        "        count = 0.0\n",
        "        model.train()\n",
        "        train_pred = []\n",
        "        train_true = []\n",
        "        for data in train_loader:\n",
        "            data, label = data['pointcloud'].to(device=device, dtype=torch.float), data['category'].to(device).squeeze()\n",
        "            data = data.permute(0, 2, 1)\n",
        "            batch_size = data.size()[0]\n",
        "            opt.zero_grad()\n",
        "            logits = model(data)\n",
        "            loss = criterion(logits, label)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            preds = logits.max(dim=1)[1]\n",
        "            count += batch_size\n",
        "            train_loss += loss.item() * batch_size\n",
        "            train_true.append(label.cpu().numpy())\n",
        "            train_pred.append(preds.detach().cpu().numpy())\n",
        "        train_true = np.concatenate(train_true)\n",
        "        train_pred = np.concatenate(train_pred)\n",
        "        # torch.save(model.state_dict(), \"save_\"+str(epoch)+\".pth\")\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': opt.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, \"dgcnn_\"+str(epoch+14)+\".pth\")\n",
        "        outstr = 'Train %d, loss: %.6f, train acc: %.6f, train avg acc: %.6f' % (epoch,\n",
        "                                                                                 train_loss*1.0/count,\n",
        "                                                                                 metrics.accuracy_score(\n",
        "                                                                                     train_true, train_pred),\n",
        "                                                                                 metrics.balanced_accuracy_score(\n",
        "                                                                                     train_true, train_pred))\n",
        "        print(outstr)\n",
        "\n",
        "        ####################\n",
        "        # Test\n",
        "        ####################\n",
        "        test_loss = 0.0\n",
        "        count = 0.0\n",
        "        model.eval()\n",
        "        test_pred = []\n",
        "        test_true = []\n",
        "        for data in test_loader:\n",
        "            data, label = data['pointcloud'].to(device=device, dtype=torch.float), data['category'].to(device).squeeze()\n",
        "            data = data.permute(0, 2, 1)\n",
        "            batch_size = data.size()[0]\n",
        "            logits = model(data)\n",
        "            loss = criterion(logits, label)\n",
        "            preds = logits.max(dim=1)[1]\n",
        "            count += batch_size\n",
        "            test_loss += loss.item() * batch_size\n",
        "            test_true.append(label.cpu().numpy())\n",
        "            test_pred.append(preds.detach().cpu().numpy())\n",
        "        test_true = np.concatenate(test_true)\n",
        "        test_pred = np.concatenate(test_pred)\n",
        "        test_acc = metrics.accuracy_score(test_true, test_pred)\n",
        "        avg_per_class_acc = metrics.balanced_accuracy_score(test_true, test_pred)\n",
        "        outstr = 'Test %d, loss: %.6f, test acc: %.6f, test avg acc: %.6f' % (epoch,\n",
        "                                                                              test_loss*1.0/count,\n",
        "                                                                              test_acc,\n",
        "                                                                              avg_per_class_acc)\n",
        "        print(outstr)\n",
        "        if test_acc >= best_test_acc:\n",
        "            best_test_acc = test_acc\n",
        "            #torch.save(model.state_dict(), 'checkpoints/%s/models/model.t7' % args.exp_name)\n",
        "            # torch.save({\n",
        "            # 'epoch': epoch,\n",
        "            # 'model_state_dict': model.state_dict(),\n",
        "            # 'optimizer_state_dict': opt.state_dict(),\n",
        "            # 'loss': loss,\n",
        "            # }, \"rgb_dgcnn_\" + str(epoch+1)+\".pth\")\n",
        "# def test(args, io):\n",
        "#     test_loader = DataLoader(ModelNet40(partition='test', num_points=args.num_points),\n",
        "#                              batch_size=args.test_batch_size, shuffle=True, drop_last=False)\n",
        "\n",
        "#     device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "\n",
        "#     #Try to load models\n",
        "#     model = DGCNN(args).to(device)\n",
        "#     model = nn.DataParallel(model)\n",
        "#     model.load_state_dict(torch.load(args.model_path))\n",
        "#     model = model.eval()\n",
        "#     test_acc = 0.0\n",
        "#     count = 0.0\n",
        "#     test_true = []\n",
        "#     test_pred = []\n",
        "#     for data, label in test_loader:\n",
        "\n",
        "#         data, label = data.to(device), label.to(device).squeeze()\n",
        "#         data = data.permute(0, 2, 1)\n",
        "#         batch_size = data.size()[0]\n",
        "#         logits = model(data)\n",
        "#         preds = logits.max(dim=1)[1]\n",
        "#         test_true.append(label.cpu().numpy())\n",
        "#         test_pred.append(preds.detach().cpu().numpy())\n",
        "#     test_true = np.concatenate(test_true)\n",
        "#     test_pred = np.concatenate(test_pred)\n",
        "#     test_acc = metrics.accuracy_score(test_true, test_pred)\n",
        "#     avg_per_class_acc = metrics.balanced_accuracy_score(test_true, test_pred)\n",
        "#     outstr = 'Test :: test acc: %.6f, test avg acc: %.6f'%(test_acc, avg_per_class_acc)\n",
        "#     io.cprint(outstr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBWMkLgQnev8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "outputId": "ef685458-daad-4337-9342-a192ebcc45b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's use 1 GPUs!\n",
            "Use Adam\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train 0, loss: 2.086810, train acc: 0.669751, train avg acc: 0.543355\n",
            "Test 0, loss: 2.018848, test acc: 0.690846, test avg acc: 0.687120\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UFuncTypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-acb2e2e33551>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-47-13d6509470f4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, train_loader, test_loader, sgd, lr, momentum)\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;34m'optimizer_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                 }, \"dgcnn_\"+str(epoch)+\"_\"+str(best_test_acc+\".pth\"))\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types (dtype('<U32'), dtype('<U32')) -> dtype('<U32')"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = DGCNN().to(device)\n",
        "model = nn.DataParallel(model)\n",
        "\n",
        "train(20, train_loader, test_loader, False, 0.0001, 0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3Odb4Zori-o"
      },
      "source": [
        "# Extracting Feature Vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkhF2SBhswTs"
      },
      "outputs": [],
      "source": [
        "path = "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoOslsJVrp7m"
      },
      "outputs": [],
      "source": [
        "unseen_test_ds = PointCloudData(path, folder='test', transform=train_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aI4-5LxUsmYO"
      },
      "outputs": [],
      "source": [
        "unseen_test_loader = DataLoader(dataset=unseen_test_ds, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gklzr9ELr591"
      },
      "outputs": [],
      "source": [
        "def knn(x, k):\n",
        "    inner = -2*torch.matmul(x.transpose(2, 1), x)\n",
        "    xx = torch.sum(x**2, dim=1, keepdim=True)\n",
        "    pairwise_distance = -xx - inner - xx.transpose(2, 1)\n",
        " \n",
        "    idx = pairwise_distance.topk(k=k, dim=-1)[1]   # (batch_size, num_points, k)\n",
        "    return idx\n",
        "\n",
        "\n",
        "def get_graph_feature(x, k=20, idx=None):\n",
        "    batch_size = x.size(0)\n",
        "    num_points = x.size(2)\n",
        "    x = x.view(batch_size, -1, num_points)\n",
        "    if idx is None:\n",
        "        idx = knn(x, k=k)   # (batch_size, num_points, k)\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "    idx_base = torch.arange(0, batch_size, device=device).view(-1, 1, 1)*num_points\n",
        "\n",
        "    idx = idx + idx_base\n",
        "\n",
        "    idx = idx.view(-1)\n",
        " \n",
        "    _, num_dims, _ = x.size()\n",
        "\n",
        "    x = x.transpose(2, 1).contiguous()   # (batch_size, num_points, num_dims)  -> (batch_size*num_points, num_dims) #   batch_size * num_points * k + range(0, batch_size*num_points)\n",
        "    feature = x.view(batch_size*num_points, -1)[idx, :]\n",
        "    feature = feature.view(batch_size, num_points, k, num_dims) \n",
        "    x = x.view(batch_size, num_points, 1, num_dims).repeat(1, 1, k, 1)\n",
        "    \n",
        "    feature = torch.cat((feature-x, x), dim=3).permute(0, 3, 1, 2).contiguous()\n",
        "  \n",
        "    return feature\n",
        "\n",
        "class DGCNN(nn.Module):\n",
        "    def __init__(self, output_channels=30):\n",
        "        super(DGCNN, self).__init__()\n",
        "        self.k = 20\n",
        "        \n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.bn5 = nn.BatchNorm1d(1024)\n",
        "\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(6, 64, kernel_size=1, bias=False),\n",
        "                                   self.bn1,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(64*2, 64, kernel_size=1, bias=False),\n",
        "                                   self.bn2,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(64*2, 128, kernel_size=1, bias=False),\n",
        "                                   self.bn3,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv4 = nn.Sequential(nn.Conv2d(128*2, 256, kernel_size=1, bias=False),\n",
        "                                   self.bn4,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.conv5 = nn.Sequential(nn.Conv1d(512, 1024, kernel_size=1, bias=False),\n",
        "                                   self.bn5,\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\n",
        "        self.linear1 = nn.Linear(1024*2, 512, bias=False)\n",
        "        self.bn6 = nn.BatchNorm1d(512)\n",
        "        self.dp1 = nn.Dropout(p=0.6)\n",
        "        self.linear2 = nn.Linear(512, 256)\n",
        "        self.bn7 = nn.BatchNorm1d(256)\n",
        "        self.dp2 = nn.Dropout(p=0.6)\n",
        "        self.linear3 = nn.Linear(256, output_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x = get_graph_feature(x, k=self.k)\n",
        "        x = self.conv1(x)\n",
        "        x1 = x.max(dim=-1, keepdim=False)[0]\n",
        "\n",
        "        x = get_graph_feature(x1, k=self.k)\n",
        "        x = self.conv2(x)\n",
        "        x2 = x.max(dim=-1, keepdim=False)[0]\n",
        "\n",
        "        x = get_graph_feature(x2, k=self.k)\n",
        "        x = self.conv3(x)\n",
        "        x3 = x.max(dim=-1, keepdim=False)[0]\n",
        "      \n",
        "        x = get_graph_feature(x3, k=self.k)\n",
        "        x = self.conv4(x)\n",
        "        x4 = x.max(dim=-1, keepdim=False)[0]\n",
        "      \n",
        "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        \n",
        "        x1 = F.adaptive_max_pool1d(x, 1).view(batch_size, -1)\n",
        "        x2 = F.adaptive_avg_pool1d(x, 1).view(batch_size, -1)\n",
        "        x = torch.cat((x1, x2), 1)\n",
        "        y = x\n",
        "        \n",
        "        x = F.leaky_relu(self.bn6(self.linear1(x)), negative_slope=0.2)\n",
        "        x = self.dp1(x)\n",
        "        x = F.leaky_relu(self.bn7(self.linear2(x)), negative_slope=0.2)\n",
        "        x = self.dp2(x)\n",
        "        x = self.linear3(x)\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePg1XiEor9LP"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-_qrnzSr963"
      },
      "outputs": [],
      "source": [
        "model = DGCNN().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DykT-tZJsEts"
      },
      "outputs": [],
      "source": [
        "model = nn.DataParallel(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlwIDyVYsQYX"
      },
      "outputs": [],
      "source": [
        "PATH = \"/content/gdrive/MyDrive/Thesis_work/DGCNN/dgcnn/pytorch/dgcnn_13_86.pth\"\n",
        "checkpoint = torch.load(PATH)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9kbqUs0sVpu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RetVOFORsZWa"
      },
      "outputs": [],
      "source": [
        "def feedforward(train_loader):\n",
        "    model.eval()\n",
        "    df = pd.DataFrame(columns=[i for i in range(2049)])\n",
        "    #feature_vector = torch.zeros([1, 1024], dtype=torch.int32).to(device) \n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        data, labels = data['pointcloud'].to(device=device, dtype=torch.float), data['category'].to(device).squeeze()\n",
        "        data = data.permute(0, 2, 1)\n",
        "        batch_size = data.size()[0]\n",
        "        output, feature_vector = model(data)\n",
        "        # inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
        "        # feature_vector, outputs = model(inputs.transpose(1,2))\n",
        "        feature_vector_np = feature_vector.cpu().detach().numpy()\n",
        "        label_np = labels.cpu().detach().numpy()\n",
        "        # print(len(label_np), feature_vector_np.shape)\n",
        "        df.loc[i] = np.append(label_np, feature_vector_np.flatten())\n",
        "        #feature_vector = torch.cat((feature_vector, vector), dim=0)\n",
        "        if i % 100 == 0:\n",
        "            print(f\"DataFrame Size {df.shape}\")\n",
        "            print(df.head(i))\n",
        "    df.to_csv('feature_vector_test_model30.csv')\n",
        "    print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSh4TMehsaiK"
      },
      "outputs": [],
      "source": [
        "feedforward(train_loader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DGCNN_new_RGBD.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "T3Odb4Zori-o"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}